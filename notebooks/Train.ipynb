{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46383908-f227-4f36-9cb5-87107ad43445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7e537f-92a3-4588-ad4e-61a1d92a5555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehmeteneserciyes/.pyenv/versions/miniconda3-latest/envs/tap/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "pybullet build time: Dec 25 2022 20:49:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to lead iql\n"
     ]
    }
   ],
   "source": [
    "import latentplan.utils as utils\n",
    "import latentplan.datasets as datasets\n",
    "from latentplan.models.vqvae import VQContinuousVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5e51cca-f365-4854-811f-483509fed49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch, numpy as np\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb84b736-eb6f-419f-b966-c9e7af7444e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e773da17-5108-475e-8ec1-6c576d5f4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: config.vqvae:hopper_medium_replay_v2\n",
      "[ utils/setup ] Not using overrides | config: config.vqvae | dataset: hopper_medium_replay_v2\n",
      "[ utils/setup ] Made savepath: /Users/mehmeteneserciyes/logs/hopper-medium-replay-v2/vae/vq/\n",
      "[ utils/setup ] Saved args to /Users/mehmeteneserciyes/logs/hopper-medium-replay-v2/vae/vq/args.json\n"
     ]
    }
   ],
   "source": [
    "class Parser(utils.Parser):\n",
    "    dataset: str = 'hopper-medium-replay-v2'\n",
    "    config: str = 'config.vqvae'\n",
    "\n",
    "#######################\n",
    "######## setup ########\n",
    "#######################\n",
    "\n",
    "args = Parser().parse_args('train')\n",
    "\n",
    "\n",
    "env_name = args.dataset if \"-v\" in args.dataset else args.dataset+\"-v0\"\n",
    "env = datasets.load_environment(env_name)\n",
    "\n",
    "sequence_length = args.subsampled_sequence_length * args.step\n",
    "args.logbase = os.path.expanduser(args.logbase)\n",
    "args.savepath = os.path.expanduser(args.savepath)\n",
    "if not os.path.exists(args.savepath):\n",
    "    os.makedirs(args.savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098c041-1869-4298-a24e-4fac34272925",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6cb3cb72-a136-41cd-83cf-323c865d079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config: <class 'latentplan.datasets.sequence.SequenceDataset'>\n",
      "    disable_goal: False\n",
      "    discount: 0.99\n",
      "    env: hopper-medium-replay-v2\n",
      "    max_path_length: 1000\n",
      "    normalize_raw: True\n",
      "    normalize_reward: True\n",
      "    penalty: -100\n",
      "    sequence_length: 25\n",
      "    step: 1\n",
      "\n",
      "Saved config to: /Users/mehmeteneserciyes/logs/hopper-medium-replay-v2/vae/vq/data_config.pkl\n",
      "\n",
      "[ datasets/sequence ] Sequence length: 25 | Step: 1 | Max path length: 1000\n",
      "[ datasets/sequence ] Loading... Downloading dataset: http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco_v2/hopper_medium_replay-v2.hdf5 to /Users/mehmeteneserciyes/.d4rl/datasets/hopper_medium_replay-v2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ datasets/sequence ] Segmenting... ✓\n",
      "Dataset size: 399958 | Joined dim: 17 (observation: 11, action: 3) | Block size: 425\n"
     ]
    }
   ],
   "source": [
    "dataset_class = datasets.SequenceDataset\n",
    "\n",
    "dataset_config = utils.Config(\n",
    "    dataset_class,\n",
    "    savepath=(args.savepath, 'data_config.pkl'),\n",
    "    env=args.dataset,\n",
    "    penalty=args.termination_penalty,\n",
    "    sequence_length=sequence_length,\n",
    "    step=args.step,\n",
    "    discount=args.discount,\n",
    "    disable_goal=args.disable_goal,\n",
    "    normalize_raw=args.normalize,\n",
    "    normalize_reward=args.normalize_reward,\n",
    "    max_path_length=int(args.max_path_length),\n",
    ")\n",
    "\n",
    "dataset = dataset_config()\n",
    "obs_dim = dataset.observation_dim\n",
    "act_dim = dataset.action_dim\n",
    "if args.task_type == \"locomotion\":\n",
    "    transition_dim = obs_dim+act_dim+3\n",
    "else:\n",
    "    transition_dim = 128+act_dim+3\n",
    "\n",
    "block_size = args.subsampled_sequence_length * transition_dim # total number of dimensionalities for a maximum length sequence (T)\n",
    "\n",
    "print(\n",
    "    f'Dataset size: {len(dataset)} | '\n",
    "    f'Joined dim: {transition_dim} '\n",
    "    f'(observation: {obs_dim}, action: {act_dim}) | Block size: {block_size}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39f1d904-4ee8-4473-8353-1cfdb4bcfcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce156a-e695-499d-8239-e8b8d037d865",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3818505b-8fa9-4532-9d18-8e76fb43b2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config: <class 'latentplan.models.vqvae.VQContinuousVAE'>\n",
      "    K: 512\n",
      "    action_dim: 3\n",
      "    action_weight: 5\n",
      "    attn_pdrop: 0.0\n",
      "    block_size: 425\n",
      "    bottleneck: pooling\n",
      "    embd_pdrop: 0.0\n",
      "    first_action_weight: 0\n",
      "    last_value_weight: 0\n",
      "    latent_step: 3\n",
      "    ma_update: True\n",
      "    masking: uniform\n",
      "    model: VQTransformer\n",
      "    n_embd: 512\n",
      "    n_head: 4\n",
      "    n_layer: 4\n",
      "    obs_shape: [-1]\n",
      "    observation_dim: 11\n",
      "    position_weight: 1\n",
      "    resid_pdrop: 0.0\n",
      "    residual: True\n",
      "    reward_weight: 1\n",
      "    state_conditional: True\n",
      "    sum_reward_weight: 0\n",
      "    trajectory_embd: 512\n",
      "    transition_dim: 17\n",
      "    value_weight: 1\n",
      "    vocab_size: 100\n",
      "\n",
      "Saved config to: /Users/mehmeteneserciyes/logs/hopper-medium-replay-v2/vae/vq/model_config.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = utils.Config(\n",
    "    VQContinuousVAE,\n",
    "    savepath=(args.savepath, 'model_config.pkl'),\n",
    "    ## discretization\n",
    "    vocab_size=args.N, block_size=block_size,\n",
    "    K=args.K,\n",
    "    ## architecture\n",
    "    n_layer=args.n_layer, n_head=args.n_head, n_embd=args.n_embd * args.n_head,\n",
    "    ## dimensions\n",
    "    observation_dim=obs_dim, action_dim=act_dim, transition_dim=transition_dim,\n",
    "    ## loss weighting\n",
    "    action_weight=args.action_weight, reward_weight=args.reward_weight, value_weight=args.value_weight,\n",
    "    position_weight=args.position_weight,\n",
    "    first_action_weight=args.first_action_weight,\n",
    "    sum_reward_weight=args.sum_reward_weight,\n",
    "    last_value_weight=args.last_value_weight,\n",
    "    trajectory_embd=args.trajectory_embd,\n",
    "    model=args.model,\n",
    "    latent_step=args.latent_step,\n",
    "    ma_update=args.ma_update,\n",
    "    residual=args.residual,\n",
    "    obs_shape=args.obs_shape,\n",
    "    ## dropout probabilities\n",
    "    embd_pdrop=args.embd_pdrop, resid_pdrop=args.resid_pdrop, attn_pdrop=args.attn_pdrop,\n",
    "    bottleneck=args.bottleneck,\n",
    "    masking=args.masking,\n",
    "    state_conditional=args.state_conditional,\n",
    ")\n",
    "\n",
    "\n",
    "model = model_config()\n",
    "if args.normalize:\n",
    "    model.set_padding_vector(dataset.normalize_joined_single(np.zeros(model.transition_dim-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14cb13e-530a-4126-babb-57f50fe70d6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7572fd32-1b0a-4689-9e4b-082333138340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "650 // model.model.transition_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "803dade1-b396-4c3b-9d52-e673b47aca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -  model.pos_emb :  12288\n",
      "2  -  model.encoder.0.ln1.weight :  512\n",
      "3  -  model.encoder.0.ln1.bias :  512\n",
      "4  -  model.encoder.0.ln2.weight :  512\n",
      "5  -  model.encoder.0.ln2.bias :  512\n",
      "6  -  model.encoder.0.attn.key.weight :  262144\n",
      "7  -  model.encoder.0.attn.key.bias :  512\n",
      "8  -  model.encoder.0.attn.query.weight :  262144\n",
      "9  -  model.encoder.0.attn.query.bias :  512\n",
      "10  -  model.encoder.0.attn.value.weight :  262144\n",
      "11  -  model.encoder.0.attn.value.bias :  512\n",
      "12  -  model.encoder.0.attn.proj.weight :  262144\n",
      "13  -  model.encoder.0.attn.proj.bias :  512\n",
      "14  -  model.encoder.0.mlp.0.weight :  1048576\n",
      "15  -  model.encoder.0.mlp.0.bias :  2048\n",
      "16  -  model.encoder.0.mlp.2.weight :  1048576\n",
      "17  -  model.encoder.0.mlp.2.bias :  512\n",
      "18  -  model.encoder.1.ln1.weight :  512\n",
      "19  -  model.encoder.1.ln1.bias :  512\n",
      "20  -  model.encoder.1.ln2.weight :  512\n",
      "21  -  model.encoder.1.ln2.bias :  512\n",
      "22  -  model.encoder.1.attn.key.weight :  262144\n",
      "23  -  model.encoder.1.attn.key.bias :  512\n",
      "24  -  model.encoder.1.attn.query.weight :  262144\n",
      "25  -  model.encoder.1.attn.query.bias :  512\n",
      "26  -  model.encoder.1.attn.value.weight :  262144\n",
      "27  -  model.encoder.1.attn.value.bias :  512\n",
      "28  -  model.encoder.1.attn.proj.weight :  262144\n",
      "29  -  model.encoder.1.attn.proj.bias :  512\n",
      "30  -  model.encoder.1.mlp.0.weight :  1048576\n",
      "31  -  model.encoder.1.mlp.0.bias :  2048\n",
      "32  -  model.encoder.1.mlp.2.weight :  1048576\n",
      "33  -  model.encoder.1.mlp.2.bias :  512\n",
      "34  -  model.encoder.2.ln1.weight :  512\n",
      "35  -  model.encoder.2.ln1.bias :  512\n",
      "36  -  model.encoder.2.ln2.weight :  512\n",
      "37  -  model.encoder.2.ln2.bias :  512\n",
      "38  -  model.encoder.2.attn.key.weight :  262144\n",
      "39  -  model.encoder.2.attn.key.bias :  512\n",
      "40  -  model.encoder.2.attn.query.weight :  262144\n",
      "41  -  model.encoder.2.attn.query.bias :  512\n",
      "42  -  model.encoder.2.attn.value.weight :  262144\n",
      "43  -  model.encoder.2.attn.value.bias :  512\n",
      "44  -  model.encoder.2.attn.proj.weight :  262144\n",
      "45  -  model.encoder.2.attn.proj.bias :  512\n",
      "46  -  model.encoder.2.mlp.0.weight :  1048576\n",
      "47  -  model.encoder.2.mlp.0.bias :  2048\n",
      "48  -  model.encoder.2.mlp.2.weight :  1048576\n",
      "49  -  model.encoder.2.mlp.2.bias :  512\n",
      "50  -  model.encoder.3.ln1.weight :  512\n",
      "51  -  model.encoder.3.ln1.bias :  512\n",
      "52  -  model.encoder.3.ln2.weight :  512\n",
      "53  -  model.encoder.3.ln2.bias :  512\n",
      "54  -  model.encoder.3.attn.key.weight :  262144\n",
      "55  -  model.encoder.3.attn.key.bias :  512\n",
      "56  -  model.encoder.3.attn.query.weight :  262144\n",
      "57  -  model.encoder.3.attn.query.bias :  512\n",
      "58  -  model.encoder.3.attn.value.weight :  262144\n",
      "59  -  model.encoder.3.attn.value.bias :  512\n",
      "60  -  model.encoder.3.attn.proj.weight :  262144\n",
      "61  -  model.encoder.3.attn.proj.bias :  512\n",
      "62  -  model.encoder.3.mlp.0.weight :  1048576\n",
      "63  -  model.encoder.3.mlp.0.bias :  2048\n",
      "64  -  model.encoder.3.mlp.2.weight :  1048576\n",
      "65  -  model.encoder.3.mlp.2.bias :  512\n",
      "66  -  model.decoder.0.ln1.weight :  512\n",
      "67  -  model.decoder.0.ln1.bias :  512\n",
      "68  -  model.decoder.0.ln2.weight :  512\n",
      "69  -  model.decoder.0.ln2.bias :  512\n",
      "70  -  model.decoder.0.attn.key.weight :  262144\n",
      "71  -  model.decoder.0.attn.key.bias :  512\n",
      "72  -  model.decoder.0.attn.query.weight :  262144\n",
      "73  -  model.decoder.0.attn.query.bias :  512\n",
      "74  -  model.decoder.0.attn.value.weight :  262144\n",
      "75  -  model.decoder.0.attn.value.bias :  512\n",
      "76  -  model.decoder.0.attn.proj.weight :  262144\n",
      "77  -  model.decoder.0.attn.proj.bias :  512\n",
      "78  -  model.decoder.0.mlp.0.weight :  1048576\n",
      "79  -  model.decoder.0.mlp.0.bias :  2048\n",
      "80  -  model.decoder.0.mlp.2.weight :  1048576\n",
      "81  -  model.decoder.0.mlp.2.bias :  512\n",
      "82  -  model.decoder.1.ln1.weight :  512\n",
      "83  -  model.decoder.1.ln1.bias :  512\n",
      "84  -  model.decoder.1.ln2.weight :  512\n",
      "85  -  model.decoder.1.ln2.bias :  512\n",
      "86  -  model.decoder.1.attn.key.weight :  262144\n",
      "87  -  model.decoder.1.attn.key.bias :  512\n",
      "88  -  model.decoder.1.attn.query.weight :  262144\n",
      "89  -  model.decoder.1.attn.query.bias :  512\n",
      "90  -  model.decoder.1.attn.value.weight :  262144\n",
      "91  -  model.decoder.1.attn.value.bias :  512\n",
      "92  -  model.decoder.1.attn.proj.weight :  262144\n",
      "93  -  model.decoder.1.attn.proj.bias :  512\n",
      "94  -  model.decoder.1.mlp.0.weight :  1048576\n",
      "95  -  model.decoder.1.mlp.0.bias :  2048\n",
      "96  -  model.decoder.1.mlp.2.weight :  1048576\n",
      "97  -  model.decoder.1.mlp.2.bias :  512\n",
      "98  -  model.decoder.2.ln1.weight :  512\n",
      "99  -  model.decoder.2.ln1.bias :  512\n",
      "100  -  model.decoder.2.ln2.weight :  512\n",
      "101  -  model.decoder.2.ln2.bias :  512\n",
      "102  -  model.decoder.2.attn.key.weight :  262144\n",
      "103  -  model.decoder.2.attn.key.bias :  512\n",
      "104  -  model.decoder.2.attn.query.weight :  262144\n",
      "105  -  model.decoder.2.attn.query.bias :  512\n",
      "106  -  model.decoder.2.attn.value.weight :  262144\n",
      "107  -  model.decoder.2.attn.value.bias :  512\n",
      "108  -  model.decoder.2.attn.proj.weight :  262144\n",
      "109  -  model.decoder.2.attn.proj.bias :  512\n",
      "110  -  model.decoder.2.mlp.0.weight :  1048576\n",
      "111  -  model.decoder.2.mlp.0.bias :  2048\n",
      "112  -  model.decoder.2.mlp.2.weight :  1048576\n",
      "113  -  model.decoder.2.mlp.2.bias :  512\n",
      "114  -  model.decoder.3.ln1.weight :  512\n",
      "115  -  model.decoder.3.ln1.bias :  512\n",
      "116  -  model.decoder.3.ln2.weight :  512\n",
      "117  -  model.decoder.3.ln2.bias :  512\n",
      "118  -  model.decoder.3.attn.key.weight :  262144\n",
      "119  -  model.decoder.3.attn.key.bias :  512\n",
      "120  -  model.decoder.3.attn.query.weight :  262144\n",
      "121  -  model.decoder.3.attn.query.bias :  512\n",
      "122  -  model.decoder.3.attn.value.weight :  262144\n",
      "123  -  model.decoder.3.attn.value.bias :  512\n",
      "124  -  model.decoder.3.attn.proj.weight :  262144\n",
      "125  -  model.decoder.3.attn.proj.bias :  512\n",
      "126  -  model.decoder.3.mlp.0.weight :  1048576\n",
      "127  -  model.decoder.3.mlp.0.bias :  2048\n",
      "128  -  model.decoder.3.mlp.2.weight :  1048576\n",
      "129  -  model.decoder.3.mlp.2.bias :  512\n",
      "130  -  model.embed.weight :  13312\n",
      "131  -  model.embed.bias :  512\n",
      "132  -  model.predict.weight :  13312\n",
      "133  -  model.predict.bias :  26\n",
      "134  -  model.cast_embed.weight :  262144\n",
      "135  -  model.cast_embed.bias :  512\n",
      "136  -  model.latent_mixing.weight :  270848\n",
      "137  -  model.latent_mixing.bias :  512\n",
      "138  -  model.ln_f.weight :  512\n",
      "139  -  model.ln_f.bias :  512\n",
      "Total params: 25793562\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_param = 0\n",
    "for name, param in model.named_parameters():\n",
    "    i+=1\n",
    "    print(i, \" - \", name, \": \", param.numel())\n",
    "    total_param += param.numel()\n",
    "print(\"Total params:\", total_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfa072-166d-459d-bac5-e264e268ff76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d4d72bc-89ff-4b7d-97ff-91b0ad4a1fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Config: <class 'latentplan.utils.training.VQTrainer'>\n",
      "    batch_size: 512\n",
      "    betas: (0.9, 0.95)\n",
      "    device: cpu\n",
      "    final_tokens: 3399643000\n",
      "    grad_norm_clip: 1.0\n",
      "    kl_warmup_tokens: 1699821500\n",
      "    learning_rate: 0.0002\n",
      "    lr_decay: False\n",
      "    num_workers: 0\n",
      "    warmup_tokens: 169982150\n",
      "    weight_decay: 0.1\n",
      "\n",
      "Saved config to: /Users/mehmeteneserciyes/logs/hopper-medium-replay-v2/vae/vq/trainer_config.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warmup_tokens = len(dataset) * block_size ## number of tokens seen per epoch\n",
    "final_tokens = 20 * warmup_tokens\n",
    "trainer_config = utils.Config(\n",
    "    utils.VQTrainer,\n",
    "    savepath=(args.savepath, 'trainer_config.pkl'),\n",
    "    # optimization parameters\n",
    "    batch_size=args.batch_size,\n",
    "    learning_rate=args.learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    grad_norm_clip=1.0,\n",
    "    weight_decay=0.1, # only applied on matmul weights\n",
    "    # learning rate decay: linear warmup followed by cosine decay to 10% of original\n",
    "    lr_decay=args.lr_decay,\n",
    "    warmup_tokens=warmup_tokens,\n",
    "    kl_warmup_tokens=warmup_tokens*10,\n",
    "    final_tokens=final_tokens,\n",
    "    ## dataloader\n",
    "    num_workers=0,\n",
    "    device=args.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48ce0319-943e-487b-b995-680388dc4c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, shuffle=False, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a569ade8-7220-4915-a9fb-b31245d7c1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = model.configure_optimizers(trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "194246fa-1e28-4e28-a51a-c2ab32407052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss #0: tensor(22.1342983, grad_fn=<MeanBackward0>)\n",
      "Loss #1: tensor(21.7037048, grad_fn=<MeanBackward0>)\n",
      "Loss #2: tensor(21.9139156, grad_fn=<MeanBackward0>)\n",
      "Loss #3: tensor(23.0029526, grad_fn=<MeanBackward0>)\n",
      "Loss #4: tensor(23.2258301, grad_fn=<MeanBackward0>)\n",
      "Loss #5: tensor(19.0901604, grad_fn=<MeanBackward0>)\n",
      "Loss #6: tensor(14.7645531, grad_fn=<MeanBackward0>)\n",
      "Loss #7: tensor(13.2855978, grad_fn=<MeanBackward0>)\n",
      "Loss #8: tensor(14.1377230, grad_fn=<MeanBackward0>)\n",
      "Loss #9: tensor(10.3079033, grad_fn=<MeanBackward0>)\n",
      "Loss #10: tensor(8.0795202, grad_fn=<MeanBackward0>)\n",
      "Loss #11: tensor(6.2094078, grad_fn=<MeanBackward0>)\n",
      "Loss #12: tensor(8.4369249, grad_fn=<MeanBackward0>)\n",
      "Loss #13: tensor(12.7121677, grad_fn=<MeanBackward0>)\n",
      "Loss #14: tensor(14.4776773, grad_fn=<MeanBackward0>)\n",
      "Loss #15: tensor(20.2491646, grad_fn=<MeanBackward0>)\n",
      "Loss #16: tensor(18.9114323, grad_fn=<MeanBackward0>)\n",
      "Loss #17: tensor(20.6282177, grad_fn=<MeanBackward0>)\n",
      "Loss #18: tensor(17.6844177, grad_fn=<MeanBackward0>)\n",
      "Loss #19: tensor(9.6011639, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch = None\n",
    "start_it = 0\n",
    "end_it = 19\n",
    "for it, batch in enumerate(loader):\n",
    "    if it < start_it:\n",
    "        continue\n",
    "    elif it > end_it:\n",
    "        break\n",
    "    reconstructed, recon_loss, vq_loss, commit_loss = model(*batch)\n",
    "    loss = (recon_loss+vq_loss+commit_loss).mean()\n",
    "    print(f\"Loss #{it}:\", loss)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), trainer_config.grad_norm_clip)\n",
    "    optimizer.step()\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5d6b4-e1dd-4ae6-8011-3f1690d9618e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tap",
   "language": "python",
   "name": "tap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
