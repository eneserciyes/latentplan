{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d87cf6-3f04-48d9-9201-c98deabcfaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f96d576-b888-4e1f-9a8b-bd71292ae5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import ipdb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70750123-5e16-4d8a-8203-5ee30ac91e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c6751-a20c-4e73-8ab3-494940cacd09",
   "metadata": {},
   "source": [
    "# nn.GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e438e3-6007-47d9-82bf-0851947aa1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0539828, 0.8413447, 1.0619165])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0539828, 0.8411920, 1.0617028])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.tensor([0.1, 1.0, 1.2])\n",
    "gelu = nn.GELU()\n",
    "gelu_approx = nn.GELU(\"tanh\")\n",
    "print(gelu(x))\n",
    "display(gelu_approx(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edaf54a-8f50-4d45-891a-891dd831d20d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CausalSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70f72e2-4722-486f-8951-841a738e22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads\n",
    "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
    "        # output projection\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "        ## mask previous value estimates\n",
    "        if \"action_dim\" in dir(config):\n",
    "            joined_dim = config.observation_dim + config.action_dim + 2\n",
    "            self.mask.squeeze()[:,joined_dim-1::joined_dim] = 0\n",
    "        ##\n",
    "        self.n_head = config.n_head\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        ## [ B x n_heads x T x head_dim ]\n",
    "        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        ## [ B x n_heads x T x T ]\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        self._attn_map = att.clone()\n",
    "        att = self.attn_drop(att)\n",
    "        ## [ B x n_heads x T x head_size ]\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        ## [ B x T x embedding_dim ]\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_drop(self.proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517a178d-ed51-4a7e-bda8-3beeef1655be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2076447, -0.1660343, -0.1446521,  0.8652914, -0.3342855,\n",
       "          -0.2586271,  0.2681955,  0.3942418],\n",
       "         [-0.0934719, -0.1169063,  0.1851222,  0.7146784, -0.1560096,\n",
       "          -0.2340157,  0.0883798,  0.0436949]],\n",
       "\n",
       "        [[-0.1535415, -0.3847658,  0.4095368,  0.3740130, -0.2884263,\n",
       "          -0.1888891, -0.4992743, -0.6241646],\n",
       "         [-0.2291546, -0.2408308,  0.1749529,  0.4173355, -0.1803498,\n",
       "          -0.2365421, -0.2945327, -0.1723328]],\n",
       "\n",
       "        [[ 0.0732064, -0.0597422,  0.1265753,  0.8852328, -0.1112194,\n",
       "          -0.2290128, -0.1146231, -0.2866505],\n",
       "         [ 0.1019692,  0.0156879,  0.3203210,  0.6205373, -0.0756834,\n",
       "          -0.0020490, -0.3810693, -0.5421953]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "cfg = Config()\n",
    "cfg.n_embd = 8\n",
    "cfg.block_size = 12\n",
    "cfg.action_dim=1\n",
    "cfg.observation_dim=2\n",
    "cfg.attn_pdrop=0.0\n",
    "cfg.resid_pdrop=0.0\n",
    "cfg.n_head = 2\n",
    "def main():\n",
    "    csa = CausalSelfAttention(cfg)\n",
    "    x = torch.randn(3, 2, 8)\n",
    "    return csa(x)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf229b-5aa9-4d94-827c-db7c23de2a4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a26d91-2971-4409-8886-87e2d185eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            nn.Dropout(config.resid_pdrop),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a9d628-d6e7-44eb-afa4-4aafd6f40636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block_test():\n",
    "    block = Block(cfg)\n",
    "    x = torch.randn(3, 2, 8)\n",
    "    return block(x)\n",
    "block_test().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd89a4-8b9d-4c8a-a957-fe6ff9389f69",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58a1bf98-fc82-4ed2-827f-02957c585fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(203424.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():\n",
    "    mask = torch.tril(torch.ones(650,650))\n",
    "    joined_dim = 25\n",
    "    mask.squeeze()[:,joined_dim-1::joined_dim] = 0\n",
    "    return mask.sum()\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8e0f8-14b9-43f1-86cc-72967efa1c50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7be8a4bc-ad24-478d-ad54-a990599cb094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3905e+00, -4.6586e-01,  7.7713e-02,  4.4452e-01,  1.4362e-01,\n",
       "         -1.8046e-01, -1.0321e+00,  1.1369e+00, -4.5345e-01, -9.0033e-01],\n",
       "        [-1.1170e-03, -1.8191e-02, -8.9934e-01,  2.9823e-01,  1.2260e+00,\n",
       "          2.1215e-01,  9.9756e-01,  1.5730e+00, -0.0000e+00, -1.6621e+00],\n",
       "        [ 1.2702e+00, -1.5433e+00,  4.2365e-01,  1.5921e+00,  2.3519e-01,\n",
       "          4.2690e-01, -9.3740e-01, -4.9528e-01, -3.7724e-01,  1.4033e+00],\n",
       "        [-1.1512e+00,  3.0650e-01, -9.3674e-02, -7.4107e-01, -6.8297e-02,\n",
       "         -1.5684e+00,  1.6519e-01, -9.2251e-02,  0.0000e+00,  4.4000e-01],\n",
       "        [-1.0474e+00,  3.4574e-02,  1.2142e+00, -1.3816e-01,  1.4342e+00,\n",
       "         -5.6411e-01, -1.2610e+00, -0.0000e+00, -1.1343e+00,  9.3370e-01],\n",
       "        [-2.0787e+00, -1.8534e-01,  1.2783e-02, -1.6651e-01,  3.5310e-02,\n",
       "          4.7878e-01, -1.2086e+00, -0.0000e+00, -4.2451e-01, -5.1759e-01],\n",
       "        [-2.2724e+00,  4.8052e-01,  2.1005e+00, -5.8680e-01, -1.1117e+00,\n",
       "          8.6624e-01,  4.7306e-01, -6.7333e-01,  1.9272e-01,  1.4821e+00],\n",
       "        [ 4.5258e-01, -5.4618e-01,  5.6025e-01, -1.1782e+00,  1.7819e-01,\n",
       "         -0.0000e+00,  5.6730e-01,  4.8646e-01, -6.7984e-01,  0.0000e+00],\n",
       "        [ 1.1470e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,  4.1499e-01,\n",
       "          1.2317e+00,  1.6405e+00,  9.2562e-01,  0.0000e+00,  8.9845e-01],\n",
       "        [-2.9152e-01,  9.1019e-01,  1.2729e+00, -1.2932e+00, -3.0773e+00,\n",
       "          1.0920e+00,  2.7340e+00, -1.4225e+00,  3.5520e-01,  9.5982e-02]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():\n",
    "    dp = nn.Dropout(0.1)\n",
    "    x = torch.randn(10,10)\n",
    "    return dp(x)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03142240-eff1-4267-9102-d53501f6d59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 1, 3, 3)\n",
    "y = torch.ones(1, 2, 3, 4)\n",
    "(x @ y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f8367-80d3-4b6d-ad89-1a853eb57592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
